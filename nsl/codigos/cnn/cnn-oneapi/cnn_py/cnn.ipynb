{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def descompactar_zip(arquivo_zip, caminho_destino):\n",
    "    with zipfile.ZipFile(arquivo_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(caminho_destino)\n",
    "    print(\"Arquivos descompactados com sucesso!\")\n",
    "\n",
    "# Declaração das variáveis\n",
    "arquivo_zip = '/content/KDD.zip'  # Substitua pelo caminho do seu arquivo ZIP\n",
    "caminho_destino = 'kdd'  # Substitua pelo caminho da pasta onde deseja descompactar\n",
    "\n",
    "# Exemplo de uso\n",
    "descompactar_zip(arquivo_zip, caminho_destino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas necessárias\n",
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import (StandardScaler, OrdinalEncoder, LabelEncoder, MinMaxScaler, OneHotEncoder)\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer, MaxAbsScaler, RobustScaler, PowerTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train = '/content/KDD/KDD/KDDTrain+.txt'\n",
    "test = '/content/KDD/KDD/KDDTest+.txt'\n",
    "test21 = '/content/KDD/KDD/KDDTest-21.arff'\n",
    "\n",
    "# Definindo variáveis para features e classes\n",
    "featureV = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\",\n",
    "            \"num_failed_logins\", \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\", \"num_shells\",\n",
    "            \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\",\n",
    "            \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "            \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\",\n",
    "            \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\", \"difficulty\"]\n",
    "\n",
    "flagV = ['OTH', 'RSTOS0', 'SF', 'SH', 'RSTO', 'S2', 'S1', 'REJ', 'S3', 'RSTR', 'S0']\n",
    "protocol_typeV = ['tcp', 'udp', 'icmp']\n",
    "serviceV = ['http', 'smtp', 'finger', 'domain_u', 'auth', 'telnet', 'ftp', 'eco_i', 'ntp_u', 'ecr_i', 'other', 'private', 'pop_3', 'ftp_data',\n",
    "            'rje', 'time', 'mtp', 'link', 'remote_job', 'gopher', 'ssh', 'name', 'whois', 'domain', 'login', 'imap4', 'daytime', 'ctf', 'nntp',\n",
    "            'shell', 'IRC', 'nnsp', 'http_443', 'exec', 'printer', 'efs', 'courier', 'uucp', 'klogin', 'kshell', 'echo', 'discard', 'systat',\n",
    "            'supdup', 'iso_tsap', 'hostnames', 'csnet_ns', 'pop_2', 'sunrpc', 'uucp_path', 'netbios_ns', 'netbios_ssn', 'netbios_dgm',\n",
    "            'sql_net', 'vmnet', 'bgp', 'Z39_50', 'ldap', 'netstat', 'urh_i', 'X11', 'urp_i', 'pm_dump', 'tftp_u', 'tim_i', 'red_i', 'icmp',\n",
    "            'http_2784', 'harvest', 'aol', 'http_8001']\n",
    "\n",
    "binary_attack = ['normal', 'ipsweep', 'nmap', 'portsweep', 'satan', 'saint', 'mscan', 'back', 'land', 'neptune', 'pod', 'smurf',\n",
    "                 'teardrop', 'apache2', 'udpstorm', 'processtable', 'mailbomb', 'buffer_overflow', 'loadmodule', 'perl', 'rootkit',\n",
    "                 'xterm', 'ps', 'sqlattack', 'ftp_write', 'guess_passwd', 'imap', 'multihop', 'phf', 'spy', 'warezclient',\n",
    "                 'warezmaster', 'snmpgetattack', 'named', 'xlock', 'xsnoop', 'sendmail', 'httptunnel', 'worm', 'snmpguess']\n",
    "\n",
    "multiclass_attack = { 'normal': 'normal',\n",
    "                      'probe': ['ipsweep.', 'nmap.', 'portsweep.', 'satan.', 'saint.', 'mscan.'],\n",
    "                      'dos': ['back.', 'land.', 'neptune.', 'pod.', 'smurf.', 'teardrop.', 'apache2.', 'udpstorm.', 'processtable.', 'mailbomb.'],\n",
    "                      'u2r': ['buffer_overflow.', 'loadmodule.', 'perl.', 'rootkit.', 'xterm.', 'ps.', 'sqlattack.'],\n",
    "                      'r2l': ['ftp_write.', 'guess_passwd.', 'imap.', 'multihop.', 'phf.', 'spy.', 'warezclient.', 'warezmaster.', 'snmpgetattack.',\n",
    "                              'named.', 'xlock.', 'xsnoop.', 'sendmail.', 'httptunnel.', 'worm.', 'snmpguess.']}\n",
    "\n",
    "# Carregar os dados\n",
    "train_data = pd.read_csv(train, names=featureV, sep=',', on_bad_lines='skip')\n",
    "test_data = pd.read_csv(test, names=featureV, sep=',', on_bad_lines='skip')\n",
    "\n",
    "test_21 = pd.read_csv(test21, names=featureV, sep=',', on_bad_lines='skip',skiprows=3)\n",
    "\n",
    "# Removendo serviços indesejados dos dados de treino e teste\n",
    "train_data = train_data.query(\"service != 'aol' and service != 'harvest' and service != 'http_2784' and service != 'http_8001' and service != 'red_i' and service != 'urh_i' and service != 'printer' and service != 'rje'\")\n",
    "test_data = test_data.query(\"service != 'printer' and service != 'rje'\")\n",
    "\n",
    "# Função para criar gráficos de barras para visualização dos dados\n",
    "def bar_graph(feature):\n",
    "    train_data[feature].value_counts().plot(kind=\"bar\")\n",
    "\n",
    "# Visualizando as features\n",
    "bar_graph('protocol_type')\n",
    "plt.figure(figsize=(15,3))\n",
    "bar_graph('service')\n",
    "bar_graph('flag')\n",
    "bar_graph('logged_in')\n",
    "bar_graph('label')\n",
    "\n",
    "# Função de pré-processamento dos dados\n",
    "def preprocessing(data, cls, df):\n",
    "    # --------- Categorizar ataques ---------\n",
    "    data['label'] = data['label'].replace(['normal.', 'normal'], 0)\n",
    "\n",
    "    # Classificação binária\n",
    "    if cls == 'binary':\n",
    "        data['label'] = data['label'].apply(lambda x: 1 if x in binary_attack else 0)\n",
    "\n",
    "    # Separar features e labels\n",
    "    y = data['label']\n",
    "    x = data.drop(columns=['label', 'difficulty'], errors='ignore')\n",
    "\n",
    "    # Detecta automaticamente colunas categóricas e aplica get_dummies\n",
    "    categorical_columns = x.select_dtypes(include=['object']).columns\n",
    "    x = pd.get_dummies(x, columns=categorical_columns)\n",
    "\n",
    "    # Normalizar as features\n",
    "    x = MinMaxScaler(feature_range=(0, 1)).fit_transform(x)\n",
    "    y = pd.get_dummies(y)\n",
    "\n",
    "    return (x, y) if df == 'train' else (x, y)\n",
    "\n",
    "\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "x_train, Y_train = preprocessing(train_data, cls='binary', df='train')\n",
    "x_test, Y_test = preprocessing(test_data, cls='binary', df='test')\n",
    "x_21_test, y_21_test = preprocessing(test_21, cls='binary', df='test21')\n",
    "\n",
    "# Ajustando dimensões das features para CNN\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "x_21_test = np.reshape(x_21_test, (x_21_test.shape[0], x_21_test.shape[1], 1))\n",
    "\n",
    "# Construindo o modelo CNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution1D(32, 3, padding=\"same\", activation=\"relu\", input_shape=(x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=(4)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(x_train, Y_train, epochs=100, batch_size=128)\n",
    "\n",
    "# Avaliando o modelo\n",
    "pred = model.predict(x_test)\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
